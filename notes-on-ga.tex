\documentclass{article}
% \usepackage{lmodern} % for any font size
% \usepackage{anyfontsize} % for any font size
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{todonotes}
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{array}
\usepackage{bm} % for bold math
\usepackage{colortbl}
\usepackage{caption}
\usepackage{chngcntr}
\usepackage{ifthen}

% ---------------------------------------------------------------------------------------------------------------------
% source of the solution: https://tex.stackexchange.com/questions/63545/big-tilde-in-math-mode
\usepackage{scalerel}
\usepackage{stackengine}
\usepackage{wasysym}
\newcommand\reallywidetilde[1]{\ThisStyle{%
  \setbox0=\hbox{$\SavedStyle#1$}%
  \stackengine{-.1\LMpt}{$\SavedStyle#1$}{%
    \stretchto{\scaleto{\SavedStyle\mkern.2mu\AC}{.5150\wd0}}{.6\ht0}%
  }{O}{c}{F}{T}{S}%
}}
% ---------------------------------------------------------------------------------------------------------------------
% to resolve conflict between bm and wasysym packages
% source: https://tex.stackexchange.com/questions/591635/wasysym-not-compatible-with-bm
\DeclareFontFamily{U}{wasy}{}
\DeclareFontShape{U}{wasy}{m}{n}{
     <-5.5> wasy5
  <5.5-6.5> wasy6
  <6.5-7.5> wasy7
  <7.5-8.5> wasy8
  <8.5-9.5> wasy9
     <9.5-> wasy10
}{}
\DeclareFontShape{U}{wasy}{b}{n}{
 <-10> ssub * wasy/m/n
 <10-> wasyb10
 }{}
\DeclareFontShape{U}{wasy}{bx}{n}{ <-> ssub * wasy/b/n}{}
\DeclareFontShape{U}{wasy}{m}{sl}{ <-> wasysl10 }{}
\DeclareFontShape{U}{wasy}{m}{it}{ <-> ssub * wasy/m/sl }{}
% ---------------------------------------------------------------------------------------------------------------------


\usepackage{fancyhdr}
\pagestyle{fancy}

% fancy title page
\usepackage{titlesec}
\titleformat{\section}
{\normalfont\Large\bfseries}{\thesection}{1em}{}[{\titlerule[0.8pt]}]

\title{Draft Notes on 3D Projective Geometric Algebra $\mathbb{G}_{(3,0,1)}$}
\author{cloudcell}
\date{April 2023}


% % \newcommand\wideTilde[1]{\accentset{\sim{}}{#1}}
% \newcommand\wideTilde[1]{\stackengine{0pt}{$#1$}{\smash{$\sim$}}{O}{c}{F}{T}{S}}


\newcounter{mytablecounter}
\counterwithin*{table}{mytablecounter}
\newcommand{\mycaption}[2][nolabel]{%
  \ifthenelse{\equal{#1}{label}}{\refstepcounter{table}\caption{#2}\label{table:\thetable}}{\caption*{#2}}%
}


\begin{document}

\maketitle  

\section{Notation}

\begin{tabbing}
    \hspace*{2cm}\=\hspace*{3cm}\=\kill
    % \mycaption[nolabel]{}
    \textbf{Main} \> \textbf{Alternative} \> \textbf{Description}\\
    $\mathbb{G}_{(3,0,1)}$ \> 3D PGA \> 3D projective geometric algebra\\
    $\mathbb{R}$ \> \> real numbers\\
    $\mathbb{C}$ \> \> complex numbers\\
    $\mathbb{H}$ \> \> quaternions\\
    % e_i - basis vectors
    $e_{i}$ \> \> basis vector, typically in an orthonormal basis\\
    $b_{i}$ \> \> basis vector in an non-orthonormal basis\\
    $a, b, A, B$ \> \> multivectors (unless redefined by context)\\
    % I - pseudoscalar
    $I_n, I$ \> \> pseudoscalar\\
    $ab$ \> \> geometric product\\
    $a^{-1}$ \> \> inverse\\
    $b / a$ \> \> right division $ba^{-1}$\\
    $a \backslash b$ \> \> left division $a^{-1}b$\\
    $a^{\star}$ \> \> dual\\
    $a^{-\star}$ \> \> undual\\
    % inverted T superscript - polarity
    $a^{\bot}$ \> $aI$ \> polarity\\
    %% tilda as a hat -- reverse
    $\tilde{a}$ \> \> reverse of $a$, which is defined as $(-1)^{grade(a)*(grade(a)-1)/2}a$ \\
    %% fat hat as a bar -- normalization
    $\hat{a}$ \> \> normalization (alternative sources may use this notation for grade involution)\\
    \> \> (grade involution of $a$ is defined as $(-1)^{grade(a)}a$) \\
    % angular brackets sub n - grade selection
    $\langle a \rangle_{k}$ \> \> $k$-grade part of a multivector $a$\\
    $grade(a)$ \> \> the grade of $a$\\
    % wedge - outer product
    $a \wedge b$ \> $\langle ab \rangle_{ s+t }$ \> outer product (also called `meet' primarily in PGA)\\
    % vee - regressive product
    $a \vee b$ \> $(a^{\star} \wedge b^{\star})^{-\star}$ \> regressive product (also called `join' primarily in PGA)\\
    % dot - inner product
    $a \cdot b$ \> $\langle a \rangle_{\vert s-t \vert}$ \> inner product (can alternatively be written as a fat dot `$\bullet$')\\
    % $a \bullet b$ \> \> inner product\\
    $a \times b$ \> $\frac{1}{2}(ab - ba)$ \> commutator product\\
    $ab\tilde{a}$ \> \> sandwich product (a term used to address all `sandwich'-like products)\\
    $a * b$ \> \> scalar product\\
    $a \rfloor b$ \> \> left contraction\\
    $a \lfloor b$ \> \> right contraction\\
    %  triple equal sign - definition
    $\equiv$ \> \> definition\\
    % lambda, mu - coefficients
    $\lambda, \mu$ \> \> scalar coefficients\\
    % i, j, k - basis vector indices
    $i, j, k$ \> \> basis vector indices\\
    %  r, s, t - grade indices
    $r, s, t$ \> \> grade indices\\
\end{tabbing}


\section{Objects}

\paragraph{}The geometric algebra of 3D projective space $\mathbb{G}_{(3,0,1)}$ is a 16-dimensional algebra generated by the following basis vectors:

\begin{itemize}
\item 1 scalar: 1,
\item 4 vectors: $e_0, e_1, e_2, e_3$,
\item 6 bivectors: $e_{01}, e_{02}, e_{03}, e_{12}, e_{31}, e_{23}$,
\item 4 trivectors: $e_{012}, e_{013}, e_{032}, e_{123}$,
\item 1 pseudoscalar: $e_{0123}$.
\end{itemize}

\paragraph{}\textbf{Multivector}: A multivector is a linear combination of blades.

\paragraph{}\textbf{Blade}: A blade is a combined geometric product of scalars and basis vectors.

\paragraph{}\textbf{Grade}: The grade of a blade is the number of basis vectors in the blade. 
The grade of a multivector is the maximum grade of its blades. A blade of grade $n$ is called an $n$-blade.

\paragraph{}\textbf{Pseudoscalar}: A pseudoscalar is an element of a geometric algebra that represents the 
highest-grade component of the algebra. In $n$-dimensional space, the pseudoscalar has a grade of $n$. It is 
formed by the geometric product of all the independent basis vectors. The pseudoscalar can be used to 
represent oriented volumes or used as an operator in various geometric transformations.

The multiples of the pseudoscalar form a one dimensional space, just as multiples of the scalar. However, 
scalars and pseudoscalars behave differently under reflections. The pseudoscalar changes sign under a
reflection, while the scalar does not. This is true when the pseudoscalar is formed from an even number of
basis vectors. If the pseudoscalar is formed from an odd number of basis vectors, then it does not change
sign under a reflection.

\section{Operations}

\subsection{\textbf{Geometric Product}}

\paragraph{}
    The GP of two multivectors $a$ and $b$ is defined as $$ab = \sum_{r,s} \langle a \rangle_{r} \langle b \rangle_{s},$$
    where $\langle a \rangle_r$ and $\langle b \rangle_s$ are the $r$-dimensional and $s$-dimensional parts of $a$ and $b$
    respectively, $r$ and $s$ are integers, $r \geq 0$, $s \geq 0$, $n$ is the dimension of the space.
    In plain English, the geometric product of two multivectors is the sum of all possible dimension (not grade) 
    combinations of the two multivectors. The GP multiplication table is shown in Table \ref{table:gp} below.

\subsubsection{\textbf{Properties of Geometric Product}}

\paragraph{}\textbf{Associativity}: GP is associative: $$(ab)c = a(bc).$$

\paragraph{}\textbf{Distributivity}: GP is distributive over addition: $$a(b+c) = ab + ac.$$

\paragraph{}\textbf{Linearity}: GP is linear in both arguments: 
$$(a+b)c = ac + bc$$ and $$a(b+c) = ab + ac.$$

\paragraph{}\textbf{Commutativity}: In general, the geometric product (GP), is neither commutative nor anti-commutative.
However, GP is commutative if and only if the vectors are parallel. 
In other words, $ab = ba$ if and only if $a \wedge b = 0$.

\subsection{\textbf{Vector Division}}

\paragraph{}
    Division, as a concept in Geometric Algebra, is slightly different from the division in scalar algebra. 
    In Geometric Algebra, division is not always possible, and when it is, it is often performed by 
    multiplying with an inverse element because Geometric Algebra deals with multivectors, which are 
    sums of scalar, vector, bivector, and higher-grade elements. 

\paragraph{}
    The vector division of two multivectors $b$ and $a$ is defined as $$b/a = ba^{-1},$$
    where $a^{-1}$ is the inverse of $a$. However, the inverse of a multivector does not always 
    exist. It typically exists only for non-degenerate multivectors, such as non-zero scalars 
    and non-degenerate blades (simple multivectors that can be factored into a product of linearly 
    independent vectors). 
    
    The general formula for the inverse of a multivector is as follows [3]:

    $$a^{-1} = \frac{\tilde{a}}{(a\tilde{a})}.$$
    
    For vectors, the inverse can be calculated as follows:

    $$a^{-1} = \frac{a}{a \cdot a} = \frac {a}{\Vert{a}\Vert^2}.$$
    
    Vectors with zero norm are not invertible. In PGA, this includes the zero vector, whose norm is zero:

    $$\Vert{e_0}\Vert^2 = e_0 \cdot e_0 = 0.$$

    

\paragraph{}\textbf{Example:} the inverse of the pseudoscalar $I_3$ (defined as $I_3 = e_1 e_2 e_3$) is defined as follows:

$$I_3^{-1} = \frac{I_3}{I_3 \cdot I_3} = \frac {I_3}{\Vert{I_3}\Vert^2} = \frac {I_3}{-1} = -I_3.$$

An inversion of a pseudoscalar is its reverse [3]: $$I_n^{-1} = \tilde{I_n}.$$

\paragraph{}\textbf{Example:} the division of a vector $a = e_{0} + e_{1} + e_{01} + e_{02}$ by a vector 
$b = e_1 + e_2 + e_{012}$ is defined as follows:

$$a/b = (e_{0} + e_{1} + e_{01} + e_{02}) / (e_1 + e_2 + e_{012})$$
$$= (e_0 + e_1 + e_{01} + e_{02})(e_1 + e_2 + e_{012})^{-1}$$
$$= (e_0 + e_1 + e_{01} + e_{02})(\reallywidetilde{e_1 + e_2 + e_{012}})/((e_1 + e_2 + e_{012})(\reallywidetilde{e_1 + e_2 + e_{012}}))$$
$$= (e_0 + e_1 + e_{01} + e_{02})({e_1 + e_2 - e_{012}})/(((e_1 + e_2 + e_{012})({e_1 + e_2 - e_{012}}))$$
$$= (e_0 + e_1 + e_{01} + e_{02})({e_1 + e_2 - e_{012}})/2 = (2 + 2e_0 - e_{01} + e_{02}) / 2$$
$$= 1 + e_0 - \frac{1}{2}e_{01} + \frac{1}{2}e_{02}.$$

 

\subsubsection{\textbf{Properties of Vector Division}}

\paragraph{}\textbf{Noncommutativity}: The division of vectors is not commutative in general. Thus, it is important to
remember that the division by a vector is not the same as the multiplication by its inverse. The side of the division
matters. For example, $$a^{-1}b \neq ba^{-1}.$$

\todo{TODO}

\subsection{\textbf{Outer Product}}

\paragraph{}
    $$A \wedge B = \sum_{r,s} \langle \langle A \rangle_{r} \langle B \rangle_{s} \rangle_{s + r}.$$
    
The outer product (or 'exterior product,' 'wedge product') of two vectors $a$ and $b$ is defined as 
$$a \wedge b = (\lambda_a e_1 + \mu_a e_2) \wedge (\lambda_b e_1 + \mu_b e_2)$$
$$= \lambda_a \lambda_b e_1 \wedge e_1 + \lambda_a \mu_b e_1 \wedge e_2 + \mu_a \lambda_b e_2 \wedge e_1 + \mu_a \mu_b e_2 \wedge e_2$$
$$= \lambda_a \mu_b e_1 \wedge e_2 + \mu_a \lambda_b e_2 \wedge e_1$$
$$= (\lambda_a \mu_b - \mu_a \lambda_b) e_1 \wedge e_2.$$

The easiest way to understand the outer product is to first consider the table defining the geometric product of two multivectors $a$ and $b$. 
The resulting multivector is formed only out of pairs of basis vectors from $a$ and $b$ that do not share a common basis vector.
Thus at multiplication, no basis vectors contract.

\subsubsection{\textbf{Properties of Outer Product}}

\paragraph{}\textbf{Asymmetry}:
$$a \wedge b = -b \wedge a.$$
\paragraph{}\textbf{Scaling}:
$$a \wedge (\lambda b) = \lambda (a \wedge b).$$
\paragraph{}\textbf{Distributivity}:
$$a \wedge (b + c) = a \wedge b + a \wedge c.$$


\subsection{\textbf{Inner Product}}

$$A\bullet B = \sum_{r,s} \langle \langle A \rangle_{r} \langle B \rangle_{s} \rangle_{\vert s - r \vert}.$$

The easiest way to understand the inner product (dot product) is to first consider the table defining the geometric product 
of two multivectors $a$ and $b$ with grades of each component of represented by $r$ and $s$, respectively.
The resulting product of each combination of components of each multivector is formed only out of pairs of basis 
vectors whose combined grade is equal to the absolute difference of the grades of units from $a$ and $b$.

That is, if the grade of the multivector component from $a$ is 3 and the grade of the multivector component from $b$ is 1, 
then the grade of the resulting multivector component must be 2. Thus the product of multivector units along $e_{013}$ and $e_{3}$
will result in a multivector unit along $e_{01}$. Thus the grades are 3 and 1, and the absolute difference in grades is 2. Such a product
ends up in the table defining the inner product. The inner product for complete multivectors is the sum of all such products. 

If, on the other hand, the grade of a multivector component from $a$ is 3 and the grade of a multivector component from $b$ is 2, 
then the grade of the \textit{valid} resulting multivector component must be 1. 
For example, the product of multivector units along $e_{013}$ and $e_{12}$ will result in a multivector unit 
along $-e_{032}$. Thus the grades are 3 and 2, and while the absolute difference is 1, the actual
product of the basis vectors has a grade of 3 rather than the needed 1. Such a product does not end up in the table defining the inner product; 
or, rather, the result of the product between such a pair of multivector units is zero.

\textbf{Example}: the inner product of two vectors $a = e_0 + e_1 + e_{01} + e_{02}$ and $b = e_1 + e_2 + e_{12}$ 
is defined as follows: $$a \cdot b = (e_0 + e_1 + e_{01} + e_{02}) \cdot (e_1 + e_2 + e_{12}) = 1 + 2e_0 + e_2.$$

\subsubsection{\textbf{Properties of Inner Product}}

\todo{TODO}

\subsection{\textbf{Scalar Product}}
$$ A * B = \sum_{r,s} \langle \langle A \rangle_{r} \langle B \rangle_{s} \rangle_{0}.$$

\subsection{\textbf{Contractions}}

\paragraph{}\textbf{Left Contraction}: The left contraction (or 'contraction onto') of a multivector $A$ with a multivector $B$ is defined as follows:

$$A\rfloor B = \sum_{r,s} \langle \langle A \rangle_{r} \langle B \rangle_{s} \rangle_{s - r}.$$

\paragraph{}\textbf{Right Contraction}: The right contraction (or 'contraction by') of a multivector $A$ with a multivector $B$ is defined as follows:

$$A\lfloor B = \sum_{r,s} \langle \langle A \rangle_{r} \langle B \rangle_{s} \rangle_{r - s}.$$

\subsection{\textbf{Commutator Product}}
The commutator product of two vectors $a$ and $b$ is defined as follows: 
$$a \times b = \frac{1}{2}(ab - ba).$$

\paragraph{}
    \textbf{Note}: The commutator product of two vectors $a$ and $b$ is equivalent to 
    the outer product of two vectors $a$ and $b$. The commutator product of a vector $a$ and a trivector $t$ 
    is equivalent to the outer product of a vector $a$ and a trivector $t$. (Can this be generalized to any odd grade?)


\subsection{\textbf{Reversion}}

\paragraph{}The reversion of a $k$-blade $A = a_1 \wedge a_2 \wedge \ldots \wedge a_k$ is defined as follows:
$$\tilde{A} = a_k \wedge \ldots \wedge a_2 \wedge a_1.$$

Equivalently, the reversion of a $k$-blade $A_k$ is defined as follows:
$$\tilde{A_k} = (-1)^{\frac{k(k-1)}{2}} A_k.$$

The reversion of a multivector $A$ is defined as follows:
$$\tilde{A} = \sum_{k}^{} (-1)^{\frac{k(k-1)}{2}} \langle A \rangle_k .$$

\subsection{\textbf{Grade Involution}}

\paragraph{}The grade involution for each grade of multivector $A$ is defined as follows:
$$involution(A_k) = (-1)^{k} A_k .$$

\subsection{\textbf{Dualization}}

\paragraph{}The dualization of a $k$-blade $A_k$ with unit pseudoscalar $I_n$ is defined as follows [3]:
$$A_k^{\star} = {A_k} \rfloor I_n^{-1}.$$

For example, in 2D space, with $I = e_1 \wedge e_2$, taking the dual twice produces the negative of the original multivector:
$$(a^\star)^\star = -\alpha e_2 \rfloor (e_1 \wedge e_2) = -\alpha e_2 \rfloor e_{12} = -\alpha e_1 = -a.$$

\subsection{\textbf{Undualization}}

\paragraph{}The undualization of a $k$-blade $A_k$ is defined as follows [3]:
$$A_k^{-\star} = A \rfloor I_n.$$

\section{Geometric Product Decompositions}

\paragraph{}\textbf{Contraction Axiom Approach to Deriving the GP}: The term `contraction' refers to the 
contraction (or reduction) of the grade after the geometric product is performed between the same basis vectors.
For example, the contraction of the GP in PGA between $e_1$ and $e_1$ is $e_1^2 = 1$.
Thus, the contraction axiom states that the square of a basis vector belongs to the set of scalars.
Hence, it is possible to construct the GP from the contraction axiom as follows:
% numbered list
\begin{enumerate}
    \item Introduce the set of scalars $\mathbb{R}$.
    \item Introduce the set of basis vectors $\{e_i\}$, also called `generators.'
    \item Define the contraction axiom: $e_i^2 = \vert e_i \vert$. \textbf{Note:} One can think of the consequence of the 
    contraction axiom is an extension of real numbers 
    with a set of \textit{new numbers} that are not included in $\mathbb{R}$, but whose square belongs to $\mathbb{R}$.
    $$e_i \notin \mathbb{R}, \quad e_i^2 \in \mathbb{R}.$$
    \item A vector $\vec{x}$ is then a linear combination of basis vectors:
    $$\vec{x} = \sum_{i}^{} x_i e_i.$$
    \item The contraction axiom is then extended to the vector $\vec{x}$ as a whole:
    $$\vec{x}^2 = \vert \vec{x} \vert^2 \Rightarrow $$
    $$\vec{x}\vec{x} = (x_1 e_1 + x_2 e_2 + \ldots + x_n e_n)(x_1 e_1 + x_2 e_2 + \ldots + x_n e_n) \Rightarrow$$
    $$ x_1^2 e_1^2 + x_2^2 e_2^2 + \ldots + x_n^2 e_n^2 + x_1 x_2 e_1 e_2 + x_1 x_3 e_1 e_3 + \ldots + x_{n-1} x_n e_{n-1} e_n \Rightarrow$$
    By definition, all the terms $e_i^2$ are scalars, and all the terms $e_i e_j$ should sum to zero if $i \neq j$.
    Thus, the contraction axiom is extended to the GP as follows:
    $$\vec{x}\vec{x} = \sum_{i}^{} x_i^2 + \sum_{i \neq j}^{} x_i x_j e_i e_j = \vert \vec{x} \vert^2.$$
    By definition, the square of a vector is a scalar, and product of the remaining terms must sum to zero.
    Thus, the following identity is true for vectors:
    $$e_i e_j = -e_j e_i, \quad i \neq j.$$
    \item Thus, the GP is the application of the following two rules:
    \subitem \textbf{Rule 1}: The square of a basis vector is a scalar:
    $$e_i^2 \in \{-1, 0, +1\}.$$
    \subitem \textbf{Rule 2}: The product of two distinct basis vectors is anticommutative:
    $$e_i e_j = -e_j e_i, \quad i \neq j.$$ 
    \item The GP can be extended to two multivectors by the following steps:
    \subitem \textbf{Step 1}: The product of two vectors is a linear combination of basis vectors $e_i$:
    $$\vec{x}\vec{y} = \sum_{i}^{} \sum_{j}^{} x_i y_j e_i e_j.$$
    If $i = j$, then $e_i e_j = e_i^2 = \vert e_i \vert^2$. 
    Thus, the GP can be written as follows:
    $$\vec{x}\vec{y} = \sum_{i}^{} \sum_{j}^{} x_i y_j e_i e_j = \sum_{i}^{} x_i y_i \vert e_i \vert^2 + \sum_{i \neq j}^{} x_i y_j (e_i e_j).$$
    \subitem \textbf{Step 2}: The above can be rewritten in terms of multivector grades:
    $$\vec{x}\vec{y} = \langle \vec{x} \vec{y} \rangle_0 + \langle \vec{x} \vec{y} \rangle_2$$
    $$ = \vec{x} \cdot \vec{y} + \vec{x} \wedge \vec{y}.$$
    \subitem \textbf{Step 3}: Extending the GP to bivectors $\vec{B}$ and $\vec{C}$, it is easy to see that their product contains 
    a scalar (when both generators contract, e.g. $e_{12} e_{12}$), a bivector (when one generator contracts, e.g. $e_{12} e_{13}$), and 
    a quadvector (when no generators contract, e.g. $e_{12} e_{34}$). Thus, the GP can be written as the sum of the following three terms:
    $$\vec{B}\vec{C} = \langle \vec{B} \vec{C} \rangle_0 + \langle \vec{B} \vec{C} \rangle_2 + \langle \vec{B} \vec{C} \rangle_4$$
    $$ = \vec{B} \cdot \vec{C} + \vec{B} \times \vec{C} + \vec{B} \wedge \vec{C}.$$
    \subitem \textbf{Step 4}: Extending the GP to arbitrary multivectors $\vec{A}$ and $\vec{B}$, 
    it is easy to see that their product contains
    a scalar (when all generators contract, e.g. $e_{12} e_{12}$), 
    a vector (when three generators contract, e.g. $e_{12} e_{234}$),
    a bivector (when two generators contract, e.g. $e_{12} e_{12} e_{34}$),
    a trivector (when one generator contracts, e.g. $e_{12} e_{23}$),
    a quadvector (when no generators contract, e.g. $e_{12} e_{34}$), and so on.
    Thus, the GP can be written as the sum of the following terms:
    $$\vec{A}\vec{B} = \langle \vec{A} \vec{B} \rangle_0 + \langle \vec{A} \vec{B} \rangle_1 + \langle \vec{A} \vec{B} \rangle_2 + \langle \vec{A} \vec{B} \rangle_3 + \langle \vec{A} \vec{B} \rangle_4 + \ldots$$
    \subitem \textbf{Step 5}: The multiplication rules for each grade can be produced using what is known as the \emph{geometric product table}, 
    also known as the \emph{Cayley table} or \emph{Clifford table}:

    The following table shows a portion of the table for the geometric product of all the basis vectors for some 
    arbitrary geometric algebra:
    \begin{center}
    % \mycaption[nolabel]{Example}
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    $\cdot$ & $1$ & $e_1$ & $e_2$ & $e_3$ & $e_4$ & $e_5$ \\
    \hline
    $1$ & $1$ & $e_1$ & $e_2$ & $e_3$ & $e_4$ & $e_5$ \\
    \hline
    $e_1$ & $e_1$ & $1$ & $e_{12}$ & $e_{13}$ & $e_{14}$ & $e_{15}$ \\
    \hline
    $e_2$ & $e_2$ & $-e_{12}$ & $1$ & $e_{23}$ & $e_{24}$ & $e_{25}$ \\
    \hline
    $e_3$ & $e_3$ & $-e_{13}$ & $-e_{23}$ & $1$ & $e_{34}$ & $e_{35}$ \\
    \hline
    $e_4$ & $e_4$ & $-e_{14}$ & $-e_{24}$ & $-e_{34}$ & $1$ & $e_{45}$ \\
    \hline
    $e_5$ & $e_5$ & $-e_{15}$ & $-e_{25}$ & $-e_{35}$ & $-e_{45}$ & $1$ \\
    \hline
    \end{tabular}
    \end{center}

    To produce the geometric product for $\mathbb{G}_{(3,0,1)}$, the following base table can be used:
    \begin{center}
    % \mycaption[]{A Portion of Cayley Table for $\mathbb{G}_{(3,0,1)}$}
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    $\cdot$ & $1$ & $e_0$ & $e_1$ & $e_2$ & $e_3$ \\
    \hline
    $1$ & $1$ & $e_0$ & $e_1$ & $e_2$ & $e_3$ \\
    \hline
    $e_0$ & $e_0$ & $0$ & $e_{01}$ & $e_{02}$ & $e_{03}$ \\
    \hline
    $e_1$ & $e_1$ & $-e_{01}$ & $1$ & $e_{12}$ & $-e_{31}$ \\
    \hline
    $e_2$ & $e_2$ & $-e_{02}$ & $-e_{12}$ & $1$ & $e_{23}$ \\
    \hline
    $e_3$ & $e_3$ & $-e_{03}$ & $e_{31}$ & $-e_{23}$ & $1$ \\
    \hline
    \end{tabular}
    \end{center}

    \paragraph{}
        You can see that the diagonal shows the product of a vector with itself, which is 1 for 3 of the vectors,
        -1 for none, and 0 for 1 basis vector pair, precisely as suggested by the $(3,0,1)$ signature.

    \paragraph{}
        You may notice that the order of the basis vectors is different in the two tables. The order of the basis 
        vectors is not important,
        as long as the order is consistent throughout the table. However, having the order of ${e_{12}, e_{23}, e_{31}}$ is 
        more convenient than ${e_{12}, e_{23}, e_{13}}$ because the basis is the same under cyclic permutation.
    \paragraph{}
        The notation ${12, 23, 31}$ is better for geometric intuition in this context because it respects the cyclic 
        permutation property. This means that if you rotate the elements in the set, you still obtain the same set, for example:
        \begin{enumerate}
            \item Original set: $\{12, 23, 31\}$
            \item Cyclic permutation 1: $\{23, 31, 12\}$
            \item Cyclic permutation 2:  $\{31, 12, 23\}$
        \end{enumerate}
    \paragraph{}
        As you can see, you still get the same set of elements, regardless of the order in which they appear. 
        This is useful when working with geometric objects like triangles or other cyclic structures, 
        as it maintains the symmetry of the underlying geometry.
    \paragraph{}
        In contrast, the set $\{12, 23, 13\}$ does not have this property. When you permute the elements in the set, 
        you get different sets:
        \begin{enumerate}
            \item Original set: $\{12, 23, 13\}$
            \item Permutation 1: $\{23, 13, 12\}$
            \item Permutation 2: $\{13, 12, 23\}$
        \end{enumerate}
        
    \paragraph{}
        These different sets correspond to different geometric configurations, which can make it harder to reason about the 
        geometry intuitively.
    \paragraph{}
        Furthermore, using a basis that respects cyclic permutation helps simplify calculations and maintain consistency 
        when working with geometric objects. It is easier to understand and visualize the geometric transformations when 
        the basis maintains the same structure under cyclic permutations.
    \paragraph{}
        By using a basis with cyclic permutation property like ${12, 23, 31}$, you avoid unnecessary complications from 
        swapping around minus signs, making the geometry more intuitive and easier to work with. For example, if we have 
        three points defining a plane at equal distances from each other and from the origin then the rotation of those 
        three points clockwise or counterclockwise by 120 degrees will intuitively correspond to the shift in coordinates 
        across those basis vectors.
    \paragraph{}
        Next, the table below expands the smaller table above using the following reasoning: the order of the indices in bivectors and trivectors
        is defined in such a way so that the all the pseudoscalar products lie on the anti-diagonal of the table. This layout is
        useful when working with the geometric product of multivectors as it allows easy identification of the location of the pseudoscalar
        product while the scalar products remain on the main diagonal of the table.
    \paragraph{}
        The expansion of the table is done by adding the basis vectors $e_{01}, e_{02}, e_{03}$ to the table and then adding the
        basis vectors $e_{12}, e_{31}, e_{23}$ to the table row and column headings in this particular order.
        The table is then expanded by adding the basis vectors $e_{021}$, $e_{013}$, $e_{032}$, $e_{123}$, and 
        $e_{0123}$ ($I$). The table is then populated by multiplying the row and column
        headings together using the geometric product between corresponding pairs of groups of basis vectors stated in 
        the rows and columns.

\end{enumerate}



    \definecolor{shcol}{RGB}{220,220,220}
    
    % reference a table gp for the geometric product
    % use narrow tabs in the table to make it fit on the page

    \begin{center}  
        \tiny % use a smaller font size for the table
        \label{table:gp} % Assign a unique label for referencing
        % \mycaption[label]{Cayley Table} % Here you define the table name
        \renewcommand{\arraystretch}{1.8}
        \begin{tabular}{|>{\columncolor{shcol}\boldmath}c@{\hspace{6pt}}|c@{\hspace{2pt}}|c@{\hspace{2pt}}|c@{\hspace{2pt}}|c@{\hspace{2pt}}|c@{\hspace{2pt}}|c@{\hspace{2pt}}|c@{\hspace{2pt}}|c@{\hspace{2pt}}|c@{\hspace{2pt}}|c@{\hspace{2pt}}|c@{\hspace{2pt}}|c@{\hspace{2pt}}|c@{\hspace{2pt}}|c@{\hspace{2pt}}|c|}
        \hline
        \rowcolor{shcol}
        \bm{$1$} & \bm{$e_{0}$}& \bm{$e_{1}$}& \bm{$e_{2}$}& \bm{$e_{3}$} & \bm{$e_{01}$} & \bm{$e_{02}$} & \bm{$e_{03}$} & \bm{$e_{12}$} & \bm{$e_{31}$} & \bm{$e_{23}$} & \bm{$e_{021}$} & \bm{$e_{013}$} & \bm{$e_{032}$} & \bm{$e_{123}$} & \bm{$I$} \\
        \hline
        $e_{0}$ & $0$ & $e_{01}$ & $e_{02}$ & $e_{03}$ & $0$ & $0$ & $0$ & $-e_{021}$ & $-e_{013}$ & $-e_{032}$ & $0$ & $0$ & $0$ & $I$ & $0$ \\
        \hline
        $e_{1}$ & $-e_{01}$ & $1$ & $e_{12}$ & $-e_{31}$ & $-e_{0}$ & $e_{021}$ & $-e_{013}$ & $e_{2}$ & $-e_{3}$ & $e_{123}$ & $e_{02}$ & $-e_{03}$ & $I$ & $e_{23}$ & $e_{032}$ \\
        \hline
        $e_{2}$ & $-e_{02}$ & $-e_{12}$ & $1$ & $e_{23}$ & $-e_{021}$ & $-e_{0}$ & $e_{032}$ & $-e_{1}$ & $e_{123}$ & $e_{3}$ & $-e_{01}$ & $I$ & $e_{03}$ & $e_{31}$ & $e_{013}$ \\
        \hline
        $e_{3}$ & $-e_{03}$ & $e_{31}$ & $-e_{23}$ & $1$ & $e_{013}$ & $-e_{032}$ & $-e_{0}$ & $e_{123}$ & $e_{1}$ & $-e_{2}$ & $I$ & $e_{01}$ & $-e_{02}$ & $e_{12}$ & $e_{021}$ \\
        \hline
        $e_{01}$ & $0$ & $e_{0}$ & $-e_{021}$ & $e_{013}$ & $0$ & $0$ & $0$ & $e_{02}$ & $-e_{03}$ & $I$ & $0$ & $0$ & $0$ & $-e_{032}$ & $0$ \\
        \hline
        $e_{02}$ & $0$ & $e_{021}$ & $e_{0}$ & $-e_{032}$ & $0$ & $0$ & $0$ & $-e_{01}$ & $I$ & $e_{03}$ & $0$ & $0$ & $0$ & $-e_{013}$ & $0$ \\
        \hline
        $e_{03}$ & $0$ & $-e_{013}$ & $e_{032}$ & $e_{0}$ & $0$ & $0$ & $0$ & $I$ & $e_{01}$ & $-e_{02}$ & $0$ & $0$ & $0$ & $-e_{021}$ & $0$ \\
        \hline
        $e_{12}$ & $-e_{021}$ & $-e_{2}$ & $e_{1}$ & $e_{123}$ & $-e_{02}$ & $e_{01}$ & $I$ & $-1$ & $e_{23}$ & $-e_{31}$ & $e_{0}$ & $e_{032}$ & $-e_{013}$ & $-e_{3}$ & $-e_{03}$ \\
        \hline
        $e_{31}$ & $-e_{013}$ & $e_{3}$ & $e_{123}$ & $-e_{1}$ & $e_{03}$ & $I$ & $-e_{01}$ & $-e_{23}$ & $-1$ & $e_{12}$ & $-e_{032}$ & $e_{0}$ & $e_{021}$ & $-e_{2}$ & $-e_{02}$ \\
        \hline
        $e_{23}$ & $-e_{032}$ & $e_{123}$ & $-e_{3}$ & $e_{2}$ & $I$ & $-e_{03}$ & $e_{02}$ & $e_{31}$ & $-e_{12}$ & $-1$ & $e_{013}$ & $-e_{021}$ & $e_{0}$ & $-e_{1}$ & $-e_{01}$ \\
        \hline
        $e_{021}$ & $0$ & $e_{02}$ & $-e_{01}$ & $-I$ & $0$ & $0$ & $0$ & $e_{0}$ & $e_{032}$ & $-e_{013}$ & $0$ & $0$ & $0$ & $e_{03}$ & $0$ \\
        \hline
        $e_{013}$ & $0$ & $-e_{03}$ & $-I$ & $e_{01}$ & $0$ & $0$ & $0$ & $-e_{032}$ & $e_{0}$ & $e_{021}$ & $0$ & $0$ & $0$ & $e_{02}$ & $0$ \\
        \hline
        $e_{032}$ & $0$ & $-I$ & $e_{03}$ & $-e_{02}$ & $0$ & $0$ & $0$ & $e_{013}$ & $-e_{021}$ & $e_{0}$ & $0$ & $0$ & $0$ & $e_{01}$ & $0$ \\
        \hline
        $e_{123}$ & $-I$ & $e_{23}$ & $e_{31}$ & $e_{12}$ & $e_{032}$ & $e_{013}$ & $e_{021}$ & $-e_{3}$ & $-e_{2}$ & $-e_{1}$ & $-e_{03}$ & $-e_{02}$ & $-e_{01}$ & $-1$ & $e_{0}$ \\
        \hline
        $I$ & $0$ & $-e_{032}$ & $-e_{013}$ & $-e_{021}$ & $0$ & $0$ & $0$ & $-e_{03}$ & $-e_{02}$ & $-e_{01}$ & $0$ & $0$ & $0$ & $-e_{0}$ & $0$ \\
        \hline
        \end{tabular}
    \end{center}





\paragraph{}\textbf{Other Decompositions of the GP}: There is only one identity that breaks the GP up into two 
mutually exclusive and collectively exhaustive parts -- 
symmetric product and antisymmetric product -- as presented in the following equation:
$$ab = \frac{1}{2}(ab + ba) + \frac{1}{2}(ab - ba).$$
Other decompositions have exceptions. For example, the decomposition of the GP into its dot and wedge parts 
is not always exhaustive.

However, if $a$ and $b$ are vectors, the following decomposition is always true:
$$ab = a \cdot b + a \wedge b.$$

If $a$ is a bivector and $b$ is an arbitrary multivector, the following decomposition is always true:
% involving an inner product, commutator product, and wedge product:
$$ab = a \rfloor b + a \times b + a \wedge b.$$


\section{Useful Identities}

\paragraph{}\textbf{Inner Product Identity} 
$$A\bullet B = A\rfloor B + A\lfloor B - A * B$$

\paragraph{}\textbf{Other Identities Involving Contractions}
$$(A \wedge B) * C = A * (B \rfloor C), \forall A,B,C.$$
$$C * (B \wedge A) = (C \lfloor B) * A, \forall A,B,C.$$


\section{References}

\todo{TODO: write this properly}
\begin{enumerate}
    \item [1] The Inner Products of Geometric Algebra by Leo Dorst
    \item [2] https://discourse.bivector.net/t/regarding-products/40/4 (Discussion of the Contraction Axiom)
    \item [3] Geometric Algebra for Computer Science by Leo Dorst, Daniel Fontijne, and Stephen Mann
    
\end{enumerate}



\end{document}
